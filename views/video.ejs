<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="/css/style.css"></style>
  <script src="https://code.jquery.com/jquery-3.7.0.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <title>Video</title>
</head>
<body>
  <header>
    <%- include('header') %>
  </header>
  <main>
    <div class="container" style="position: relative; z-index: -5;">
      <button class="my-btn" style="position:absolute; top:70px; left: 300px; font-size:35px;" onclick="app()" id="cam-btn">Play</button>
      <video id="video" width="640" height="480" autoplay playsinline muted style="position:absolute; top:170px; left: 300px;;"></video>
      <canvas id="canvas" width="640" height="480" style="position:absolute; top:170px; left: 300px;"></canvas>
      <canvas id="output_canvas" width="640" height="480" style="position:absolute; top:0; right:0;"></canvas>
    </div>
  </main>
</body>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"> </script>
<script>
    const userInfo = JSON.parse('<%-JSON.stringify(user)%>');
    const patternLink = document.getElementById('pattern-btn');
    patternLink.href = `/user/${userInfo.id}/pattern`
    const ringLink = document.getElementById('ring-btn');
    ringLink.href = `/user/${userInfo.id}/ring`

    let animationFrame;
    const video = document.getElementById("video");

    const camBtn = document.getElementById('cam-btn');
    camBtn.addEventListener('click',function(){
      if(stopVideo){
        app();
        stopVideo = false;
      }
      else{
        window.cancelAnimationFrame(animationFrame);
        video.srcObject = null;
        camBtn.textContent = 'Play';
        stopVideo = true;
      }
    });
    
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");
    
    const output_canvas = document.getElementById("output_canvas");
    const output_context = output_canvas.getContext("2d");
    
    const WIDTH = canvas.width;
    const HEIGHT = canvas.height;

    let boxWidth, boxHeigth, boxX, boxY, probability;
    let webcam, lodel;

    async function app() {
        camBtn.textContent = 'Stop';
        webcam = await navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        video.srcObject = webcam;
        model = await blazeface.load();
        eyeModel = await tf.loadLayersModel('https://raw.githubusercontent.com/uniqquej/tfjs/main/eyes_tfjs_model/model.json');
        loop();
    }
    async function loop() {
        const pred = await model.estimateFaces(video, false);
        context.drawImage(video, 0, 0, 640, 480);
        if (pred.length > 0) {
            boxX = pred[0].topLeft[0];
            boxY = pred[0].topLeft[1];
            boxWidth = pred[0].bottomRight[0] - boxX;
            boxHeigth = pred[0].bottomRight[0] - boxY;
            probability = pred[0].probability[0];
            landmarks = pred[0].landmarks;
    
            context.beginPath();
            context.lineWidth = 2;
            context.strokeStyle = "#00ff00";
            context.strokeRect(boxX, boxY, boxWidth, boxHeigth);   
            context.font = "25px Arial";
            context.fillStyle = "#ffffff";
            context.fillText(`${parseFloat(probability).toFixed(2)}`, boxX, boxY);
            context.fillStyle = "#ff0000";
            context.fillRect(landmarks[0][0], landmarks[0][1], 5, 5);
            context.fillRect(landmarks[1][0], landmarks[1][1], 5, 5);
        
            output_canvas.width = boxWidth;
            output_canvas.height = boxHeigth;

            output_context.drawImage(video, boxX, boxY, boxWidth, boxHeigth, 0, 0, boxWidth, boxHeigth );
                            
            let tensor = tf.browser.fromPixels(output_canvas);
            tensor = tensor.resizeNearestNeighbor([224, 224]).div(255.0);
            let x_test = tensor.expandDims(0);
            
            const eye_pred = eyeModel.predict(x_test).arraySync();
            console.log(eye_pred[0]);
        }
        
        animationFrame = requestAnimationFrame(loop);
    }
</script>
</html>